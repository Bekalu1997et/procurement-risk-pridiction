{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 - Explainability with SHAP\n",
        "\n",
        "Compute SHAP values for trained models and generate a Mistral-backed narrative.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src import data_pipeline, explainability, model_pipeline, visualization\n",
        "\n",
        "X, y = data_pipeline.prepare_training_data()\n",
        "sample = X.sample(1, random_state=42)\n",
        "result = model_pipeline.predict_single(\"random_forest\", sample.iloc[0].to_dict())\n",
        "explanation = explainability.build_explanation(\n",
        "    risk_level=result[\"prediction\"],\n",
        "    probabilities=result[\"probabilities\"],\n",
        "    shap_values=result[\"shap_values\"],\n",
        "    feature_names=result[\"feature_names\"],\n",
        ")\n",
        "\n",
        "visualization.plot_shap_summary(explanation.shap_values, explanation.feature_names, \"notebook_shap\")\n",
        "explanation.narrative\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
