{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete MLOps Pipeline Demo\n",
    "## End-to-End Supplier Risk Prediction System\n",
    "\n",
    "**Purpose**: Demonstrate the complete data flow through all pipeline components:\n",
    "- Data Pipeline ‚Üí Feature Engineering ‚Üí Model Training ‚Üí Prediction\n",
    "- Auditing ‚Üí Explainability ‚Üí NLP ‚Üí Visualization ‚Üí Recommendations\n",
    "\n",
    "**Why This Matters**: Shows how all components work together in production MLOps workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n",
    "**What**: Import all pipeline components\n",
    "**Why**: Each module handles a specific part of the ML lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database initialized successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DABC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì All pipeline components imported successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add project root to path\n",
    "BASE_DIR = Path.cwd().parent\n",
    "sys.path.insert(0, str(BASE_DIR))\n",
    "\n",
    "# Import all pipeline components\n",
    "from src import data_pipeline      # Data loading & preprocessing\n",
    "from src import model_pipeline     # Model training & prediction\n",
    "from src import explainability     # SHAP + LLM explanations\n",
    "from src import nlp_layer          # NLP features & summarization\n",
    "from src import auditing           # Data quality & logging\n",
    "from src import visualization      # Charts & plots\n",
    "from src import recommendation     # Business recommendations\n",
    "from backend import visualization_engine  # Advanced visualizations\n",
    "from backend import explainability_viz    # SHAP visualizations\n",
    "\n",
    "print(\"‚úì All pipeline components imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline - Load & Preprocess\n",
    "**What**: Load raw data and prepare for modeling\n",
    "**Why**: Clean, validated data is foundation of ML success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STEP 1: Data Pipeline\n",
      "Training data shape: (10500, 26)\n",
      "Weekly data shape: (10500, 27)\n",
      "\n",
      "Columns: ['supplier_id', 'company_name', 'region', 'industry', 'annual_revenue', 'annual_spend', 'avg_payment_delay_days', 'contract_value', 'contract_duration_months', 'past_disputes']...\n",
      "\n",
      " Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "print(\" STEP 1: Data Pipeline\")\n",
    "\n",
    "training_df, weekly_df = data_pipeline.load_processed_datasets()\n",
    "\n",
    "print(f\"Training data shape: {training_df.shape}\")\n",
    "print(f\"Weekly data shape: {weekly_df.shape}\")\n",
    "print(f\"\\nColumns: {list(training_df.columns[:10])}...\")\n",
    "print(\"\\n Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Auditing Pipeline - Data Quality Checks\n",
    "**What**: Validate data quality and log metrics\n",
    "**Why**: Catch data issues before they break models (garbage in = garbage out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " STEP 2: Auditing Pipeline\n",
      "======================================================================\n",
      "\n",
      "Data Quality Report:\n",
      "                metric  value  threshold  passed\n",
      "0       max_null_ratio    0.0       0.15    True\n",
      "1  region_domain_check    0.0       0.00    True\n",
      "\n",
      "‚úì Data quality validated and logged\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n STEP 2: Auditing Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Run data quality checks\n",
    "quality_report = auditing.log_data_quality(training_df)\n",
    "\n",
    "print(\"\\nData Quality Report:\")\n",
    "print(quality_report.head(10))\n",
    "\n",
    "# Log audit event\n",
    "auditing.persist_audit_log(\n",
    "    event_type=\"pipeline_execution\",\n",
    "    payload={\n",
    "        \"stage\": \"data_quality_check\",\n",
    "        \"rows\": len(training_df),\n",
    "        \"columns\": len(training_df.columns)\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Data quality validated and logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - Prepare Training Data\n",
    "**What**: Split features (X) and target (y)\n",
    "**Why**: Models need clean separation of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " STEP 3: Feature Engineering\n",
      "======================================================================\n",
      "Features (X) shape: (10500, 9)\n",
      "Target (y) shape: (10500,)\n",
      "\n",
      "Feature columns: ['region', 'industry', 'contract_criticality', 'annual_spend', 'credit_score', 'late_ratio', 'dispute_rate', 'avg_delay', 'clause_risk_score']...\n",
      "\n",
      "Target distribution:\n",
      "risk_label\n",
      "medium    3943\n",
      "high      3743\n",
      "low       2814\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Features prepared for training\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n STEP 3: Feature Engineering\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "X, y = data_pipeline.prepare_training_data()\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns[:10])}...\")\n",
    "print(f\"\\nTarget distribution:\\n{y.value_counts()}\")\n",
    "print(\"\\n‚úì Features prepared for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Pipeline - Train Models\n",
    "**What**: Train Random Forest and XGBoost models\n",
    "**Why**: Ensemble models provide robust predictions with feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " STEP 4: Model Training\n",
      "======================================================================\n",
      "\n",
      "Model Training Complete:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m artifacts = model_pipeline.train_models(X, y)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel Training Complete:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_name, metrics \u001b[38;5;129;01min\u001b[39;00m \u001b[43martifacts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m():\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics.get(\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mN/A\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "print(\"\\n STEP 4: Model Training\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Train models\n",
    "artifacts = model_pipeline.train_models(X, y)\n",
    "\n",
    "print(\"\\nModel Training Complete:\")\n",
    "for model_name, metrics in artifacts.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy: {metrics.get('accuracy', 'N/A')}\")\n",
    "    print(f\"  Model saved: {metrics.get('model_path', 'N/A')}\")\n",
    "\n",
    "print(\"\\n‚úì Models trained and persisted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Prediction Pipeline - Single Supplier Prediction\n",
    "**What**: Predict risk for a single supplier\n",
    "**Why**: Real-time predictions for procurement decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n STEP 5: Prediction Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create test supplier\n",
    "test_supplier = {\n",
    "    \"region\": \"North America\",\n",
    "    \"industry\": \"Manufacturing\",\n",
    "    \"contract_criticality\": \"High\",\n",
    "    \"annual_revenue\": 2000000.0,\n",
    "    \"annual_spend\": 75000.0,\n",
    "    \"avg_payment_delay_days\": 10.0,\n",
    "    \"contract_value\": 150000.0,\n",
    "    \"contract_duration_months\": 12,\n",
    "    \"past_disputes\": 2,\n",
    "    \"delivery_score\": 70.0,\n",
    "    \"financial_stability_index\": 60.0,\n",
    "    \"relationship_years\": 3,\n",
    "    \"txn_count\": 80,\n",
    "    \"avg_txn_amount\": 3000.0,\n",
    "    \"avg_delay\": 8.0,\n",
    "    \"late_ratio\": 0.15,\n",
    "    \"dispute_rate\": 0.08,\n",
    "    \"avg_delivery_quality\": 68.0,\n",
    "    \"clause_risk_score\": 45.0,\n",
    "    \"credit_score\": 650\n",
    "}\n",
    "\n",
    "# Make prediction\n",
    "result = model_pipeline.predict_single(\"random_forest\", test_supplier)\n",
    "\n",
    "print(f\"\\nPrediction: {result['prediction'].upper()}\")\n",
    "print(f\"\\nProbabilities:\")\n",
    "for risk_level, prob in result['probabilities'].items():\n",
    "    print(f\"  {risk_level}: {prob*100:.2f}%\")\n",
    "\n",
    "print(\"\\n‚úì Prediction generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Explainability Pipeline - SHAP + LLM Narratives\n",
    "**What**: Generate human-friendly explanations using SHAP and Ollama\n",
    "**Why**: Regulatory compliance and user trust require explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n STEP 6: Explainability Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Build explanation\n",
    "explanation = explainability.build_explanation(\n",
    "    risk_level=result['prediction'],\n",
    "    probabilities=result['probabilities'],\n",
    "    shap_values=result['shap_values'],\n",
    "    feature_names=result['feature_names']\n",
    ")\n",
    "\n",
    "print(f\"\\nRisk Level: {explanation.risk_level.upper()}\")\n",
    "print(f\"Confidence: {explanation.confidence}%\")\n",
    "\n",
    "print(f\"\\nTop 5 Contributing Features:\")\n",
    "for feat, val in explanation.top_features[:5]:\n",
    "    impact = \"increases\" if val > 0 else \"decreases\"\n",
    "    print(f\"  {feat}: {val:.4f} ({impact} risk)\")\n",
    "\n",
    "print(f\"\\nBusiness Narrative:\")\n",
    "print(f\"  {explanation.narrative}\")\n",
    "\n",
    "print(\"\\n‚úì Explanation generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. NLP Pipeline - Feature Summarization\n",
    "**What**: Use NLP to summarize SHAP features\n",
    "**Why**: Translate technical features to business language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n STEP 7: NLP Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Summarize SHAP values using NLP\n",
    "top_features_nlp = nlp_layer.summarize_shap_values(\n",
    "    result['shap_values'],\n",
    "    result['feature_names'],\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(\"\\nNLP-Enhanced Feature Summary:\")\n",
    "for feat, val in top_features_nlp:\n",
    "    clean_name = feat.replace('numeric__', '').replace('categorical__', '').replace('_', ' ').title()\n",
    "    print(f\"  ‚Ä¢ {clean_name}: {val:.4f}\")\n",
    "\n",
    "print(\"\\n‚úì NLP summarization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Recommendation Pipeline - Actionable Insights\n",
    "**What**: Generate business recommendations based on risk\n",
    "**Why**: Predictions without actions are useless - provide next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n STEP 8: Recommendation Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = recommendation.build_recommendations(\n",
    "    risk_level=explanation.risk_level,\n",
    "    top_features=explanation.top_features\n",
    ")\n",
    "\n",
    "print(\"\\nActionable Recommendations:\")\n",
    "for i, reco in enumerate(recommendations, 1):\n",
    "    print(f\"  {i}. {reco}\")\n",
    "\n",
    "print(\"\\n‚úì Recommendations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualization Pipeline - Feature Importance\n",
    "**What**: Create visual explanations of SHAP values\n",
    "**Why**: Visualizations help stakeholders understand model decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n STEP 9: Visualization Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Generate SHAP summary plot\n",
    "shap_plot_path = visualization.plot_shap_summary(\n",
    "    explanation.shap_values,\n",
    "    explanation.feature_names,\n",
    "    output_name=\"pipeline_demo_shap\"\n",
    ")\n",
    "\n",
    "print(f\"\\nSHAP plot saved: {shap_plot_path}\")\n",
    "\n",
    "# Generate feature importance plot\n",
    "importance_plot_path = explainability_viz.plot_feature_importance(\n",
    "    explanation.feature_names,\n",
    "    explanation.shap_values,\n",
    "    output_name=\"pipeline_demo_importance\"\n",
    ")\n",
    "\n",
    "print(f\"Feature importance plot saved: {importance_plot_path}\")\n",
    "\n",
    "print(\"\\n‚úì Visualizations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Visualization - Data Exploration\n",
    "**What**: Create advanced charts for data analysis\n",
    "**Why**: Understand data distributions and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n STEP 10: Advanced Visualization\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create correlation heatmap\n",
    "heatmap_path = visualization_engine.heatmap(\n",
    "    training_df,\n",
    "    output_name=\"pipeline_demo_heatmap\"\n",
    ")\n",
    "\n",
    "print(f\"\\nHeatmap saved: {heatmap_path}\")\n",
    "\n",
    "# Create histogram\n",
    "hist_path = visualization_engine.histogram(\n",
    "    training_df,\n",
    "    column=\"credit_score\",\n",
    "    output_name=\"pipeline_demo_histogram\"\n",
    ")\n",
    "\n",
    "print(f\"Histogram saved: {hist_path}\")\n",
    "\n",
    "print(\"\\n‚úì Advanced visualizations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Audit Trail - Log Complete Pipeline Execution\n",
    "**What**: Log all pipeline steps for compliance and debugging\n",
    "**Why**: Production systems need complete audit trails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìù STEP 11: Audit Trail\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Log complete pipeline execution\n",
    "auditing.persist_audit_log(\n",
    "    event_type=\"complete_pipeline_execution\",\n",
    "    payload={\n",
    "        \"supplier_id\": \"DEMO_001\",\n",
    "        \"prediction\": result['prediction'],\n",
    "        \"confidence\": explanation.confidence,\n",
    "        \"top_features\": [f[0] for f in explanation.top_features[:3]],\n",
    "        \"recommendations_count\": len(recommendations),\n",
    "        \"visualizations_generated\": 4\n",
    "    }\n",
    ")\n",
    "\n",
    "# Fetch recent audit events\n",
    "recent_events = auditing.db_connector.fetch_audit_trail(limit=5)\n",
    "\n",
    "print(\"\\nRecent Audit Events:\")\n",
    "print(recent_events[['event_type', 'timestamp']].head())\n",
    "\n",
    "print(\"\\n‚úì Pipeline execution logged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Complete Pipeline Summary\n",
    "**What**: Summarize entire MLOps workflow\n",
    "**Why**: Show how all components integrate for production ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ COMPLETE MLOPS PIPELINE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "‚úì Data Pipeline: Loaded {len(training_df)} training records\n",
    "‚úì Auditing: Validated data quality and logged events\n",
    "‚úì Feature Engineering: Prepared {X.shape[1]} features\n",
    "‚úì Model Training: Trained Random Forest and XGBoost\n",
    "‚úì Prediction: Generated {result['prediction'].upper()} risk prediction\n",
    "‚úì Explainability: Created SHAP + LLM narrative\n",
    "‚úì NLP: Summarized top {len(top_features_nlp)} features\n",
    "‚úì Recommendations: Generated {len(recommendations)} action items\n",
    "‚úì Visualization: Created 4 charts and plots\n",
    "‚úì Audit Trail: Logged complete pipeline execution\n",
    "\n",
    "Pipeline Components Used:\n",
    "  ‚Ä¢ data_pipeline: Data loading & preprocessing\n",
    "  ‚Ä¢ model_pipeline: Training & prediction\n",
    "  ‚Ä¢ explainability: SHAP + Ollama narratives\n",
    "  ‚Ä¢ nlp_layer: Feature summarization\n",
    "  ‚Ä¢ auditing: Quality checks & logging\n",
    "  ‚Ä¢ visualization: SHAP plots\n",
    "  ‚Ä¢ visualization_engine: Advanced charts\n",
    "  ‚Ä¢ explainability_viz: Feature importance\n",
    "  ‚Ä¢ recommendation: Business actions\n",
    "\n",
    "This demonstrates a complete production MLOps workflow!\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
