{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Model Training\n",
        "\n",
        "Train RandomForest and XGBoost models using the modular `model_pipeline` utilities and capture auditing metadata.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'random_forest': 0.6266885220100604}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# Ensure the repository root and src directory are on sys.path before importing project modules\n",
        "BASE_DIR = Path(\"..\").resolve()\n",
        "sys.path.insert(0, str(BASE_DIR))\n",
        "sys.path.insert(0, str(BASE_DIR / \"src\"))\n",
        "from src import data_pipeline, model_pipeline\n",
        "\n",
        "X, y = data_pipeline.prepare_training_data()\n",
        "artifacts = model_pipeline.train_models(X, y)\n",
        "\n",
        "{artifact.model_name: artifact.report[\"macro avg\"][\"f1-score\"] for artifact in artifacts}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sample = X.iloc[\u001b[32m0\u001b[39m].to_dict()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_single\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrandom_forest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\ai_procurment_manager\\risk_prediction_system_production_demo\\src\\model_pipeline.py:226\u001b[39m, in \u001b[36mpredict_single\u001b[39m\u001b[34m(model_name, features)\u001b[39m\n\u001b[32m    214\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m    215\u001b[39m     X, y, test_size=\u001b[32m0.2\u001b[39m, stratify=y, random_state=\u001b[32m42\u001b[39m\n\u001b[32m    216\u001b[39m )\n\u001b[32m    218\u001b[39m rf_pipeline = Pipeline(\n\u001b[32m    219\u001b[39m     steps=[\n\u001b[32m    220\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mpreprocessor\u001b[39m\u001b[33m\"\u001b[39m, preprocessor),\n\u001b[32m    221\u001b[39m         (\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, RandomForestClassifier(random_state=\u001b[32m42\u001b[39m)),\n\u001b[32m    222\u001b[39m     ]\n\u001b[32m    223\u001b[39m )\n\u001b[32m    224\u001b[39m artifacts = [\n\u001b[32m    225\u001b[39m     _train_single_model(\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m         model_name=\u001b[33m\"\u001b[39m\u001b[33mrandom_forest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         estimator=rf_pipeline,\n\u001b[32m    228\u001b[39m         param_grid=config[\u001b[33m\"\u001b[39m\u001b[33mrandom_forest\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    229\u001b[39m         X_train=X_train,\n\u001b[32m    230\u001b[39m         y_train=y_train,\n\u001b[32m    231\u001b[39m         X_test=X_test,\n\u001b[32m    232\u001b[39m         y_test=y_test,\n\u001b[32m    233\u001b[39m     )\n\u001b[32m    234\u001b[39m ]\n\u001b[32m    236\u001b[39m MODELS_DIR.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Ensure models directory exists\u001b[39;00m\n\u001b[32m    238\u001b[39m metadata_path = MODELS_DIR / \u001b[33m\"\u001b[39m\u001b[33mlatest_training_summary.json\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ],
      "source": [
        "sample = X.iloc[0].to_dict()\n",
        "model_pipeline.predict_single(\"random_forest\", sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models dir: C:\\Users\\DABC\\Desktop\\ai_procurment_manager\\risk_prediction_system_production_demo\\models\n",
            "Loaded pipeline type: <class 'sklearn.pipeline.Pipeline'>\n",
            "Sample df columns: ['region', 'industry', 'contract_criticality', 'annual_spend', 'credit_score', 'late_ratio', 'dispute_rate', 'avg_delay', 'clause_risk_score']\n",
            "Calling pipeline.predict...\n",
            "['medium']\n",
            "Calling pipeline.predict_proba...\n",
            "[[0.28306066 0.24241028 0.47452906]]\n"
          ]
        }
      ],
      "source": [
        "# Debug: inspect loaded pipeline and run predict step-by-step\n",
        "from src import model_pipeline\n",
        "print('Models dir:', model_pipeline.MODELS_DIR)\n",
        "pl = model_pipeline.load_model('random_forest')\n",
        "print('Loaded pipeline type:', type(pl))\n",
        "sample_df = pd.DataFrame([sample])[pl.named_steps['preprocessor'].transformers[0][2] + pl.named_steps['preprocessor'].transformers[1][2]]\n",
        "print('Sample df columns:', sample_df.columns.tolist())\n",
        "print('Calling pipeline.predict...')\n",
        "print(pl.predict(sample_df))\n",
        "print('Calling pipeline.predict_proba...')\n",
        "print(pl.predict_proba(sample_df))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
